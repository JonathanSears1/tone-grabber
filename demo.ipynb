{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo Notebook for Tone Grabber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Generator Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the effects and effect parameter mappings for the dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.data_generator import DataGenerator\n",
    "from pedalboard import Reverb, Delay, Chorus, Distortion, Gain\n",
    "import torch\n",
    "# Dictionary of effects to parameter mappings\n",
    "effects_to_parameters = {\n",
    "    \"Reverb\": {\n",
    "        \"room_size\": (0, 1),\n",
    "        \"damping\": (0, 1), \n",
    "        \"wet_level\": (0, 1),\n",
    "        \"dry_level\": (0, 1),\n",
    "        \"width\": (0, 1),\n",
    "        \"freeze_mode\": (0, 1)\n",
    "    },\n",
    "    \"Delay\": {\n",
    "        \"delay_seconds\": (0, 2),\n",
    "        \"feedback\": (0, 1),\n",
    "        \"mix\": (0, 1)\n",
    "    },\n",
    "    \"Chorus\": {\n",
    "        \"rate_hz\": (0, 100),\n",
    "        \"depth\": (0, 1),\n",
    "        \"centre_delay_ms\": (1, 30),\n",
    "        \"feedback\": (0, 1),\n",
    "        \"mix\": (0, 1)\n",
    "    },\n",
    "    \"Distortion\": {\n",
    "        \"drive_db\": (0, 100)\n",
    "    },\n",
    "    \"Gain\": {\n",
    "        \"gain_db\": (-12, 12)\n",
    "    }\n",
    "}\n",
    "# List of effects\n",
    "effects = [Reverb, Delay, Distortion, Gain, Chorus]\n",
    "\n",
    "# create instance of data generator corresponding to effects\n",
    "generator = DataGenerator(effects_to_parameters, effects)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a demo dataset with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 64.77it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# num samples is the number of samples created per audio effect so total number of samples created will be:\n",
    "# num_samples * number of dry_tones\n",
    "num_samples = 2\n",
    "audio_directory = os.path.join(os.getcwd(),\"demo_data\")\n",
    "dry_tones = os.listdir(audio_directory)\n",
    "# max_chain_length is the maximum number of effects applied to a sample\n",
    "max_chain_length = 1\n",
    "demo_dataset = generator.create_data(num_samples,audio_directory,dry_tones,max_chain_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each entry of the dataset has this output signature:\n",
    "\n",
    "```\n",
    "\"dry_tone\": \n",
    "{\n",
    "    \"spectrogram\":log mel spectrogram of the dry tone,\n",
    "    \"loudness\":loudness of the dry tone,\n",
    "    \"f0\":fundamental frequency of the dry tone,\n",
    "    \"path\":path to the original dry tone\n",
    "}\n",
    "```\n",
    "\n",
    "```\n",
    "\"wet_tone\": {\n",
    "    \"spectrogram\":log mel spectrogram of the wet tone,\n",
    "    \"loudness\":loudness of the wet tone\n",
    "    \"f0\":fundamental frequency of the wet tone,\n",
    "    \"path\":path to the original wet tone\n",
    "}\n",
    "```\n",
    "```\n",
    "\"effect_names\":names of the applied effect(s)\n",
    "```\n",
    "```\n",
    "\"effects\":one-hot encoding representation of the effects\n",
    "```\n",
    "```\n",
    "\"parameters\": one-hot like representation of the effect parameters\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dry_tone': {'spectrogram': tensor([[[ 0.4758,  0.1692,  0.5460,  ..., -0.8662, -0.8763, -0.8942],\n",
       "           [ 0.4337,  0.0829,  0.4597,  ..., -0.9494, -0.8654, -0.9873],\n",
       "           [ 0.2219, -0.0940,  0.2828,  ..., -0.9795, -0.8412, -0.9774],\n",
       "           ...,\n",
       "           [ 0.4670,  0.4670,  0.4670,  ...,  0.4670,  0.4670,  0.4670],\n",
       "           [ 0.4670,  0.4670,  0.4670,  ...,  0.4670,  0.4670,  0.4670],\n",
       "           [ 0.4670,  0.4670,  0.4670,  ...,  0.4670,  0.4670,  0.4670]]]),\n",
       "  'path': '/home/jonat/tone-grabber/demo_data/guitar_acoustic_017-102-050.wav'},\n",
       " 'wet_tone': {'spectrogram': tensor([[[ 0.5192,  0.2126,  0.5894,  ..., -0.8228, -0.8329, -0.8509],\n",
       "           [ 0.4770,  0.1262,  0.5031,  ..., -0.9061, -0.8220, -0.9438],\n",
       "           [ 0.2653, -0.0506,  0.3262,  ..., -0.9362, -0.7979, -0.9341],\n",
       "           ...,\n",
       "           [ 0.4670,  0.4670,  0.4670,  ...,  0.4670,  0.4670,  0.4670],\n",
       "           [ 0.4670,  0.4670,  0.4670,  ...,  0.4670,  0.4670,  0.4670],\n",
       "           [ 0.4670,  0.4670,  0.4670,  ...,  0.4670,  0.4670,  0.4670]]])},\n",
       " 'effect_names': ['Reverb'],\n",
       " 'effects': tensor([1., 0., 0., 0., 0.]),\n",
       " 'parameters': tensor([0.3732, 0.6315, 0.1278, 0.6095, 0.3918, 0.2247, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(demo_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also get the metadata for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'parameter_mask_str': {'Reverb': [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'Delay': [0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'Chorus': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0],\n",
       "  'Distortion': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "  'Gain': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]},\n",
       " 'parameter_mask_idx': {0: [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  1: [0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "  4: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0],\n",
       "  2: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "  3: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]},\n",
       " 'effect_to_idx': {'Reverb': 0,\n",
       "  'Delay': 1,\n",
       "  'Distortion': 2,\n",
       "  'Gain': 3,\n",
       "  'Chorus': 4},\n",
       " 'index_to_effect': {0: 'Reverb',\n",
       "  1: 'Delay',\n",
       "  2: 'Distortion',\n",
       "  3: 'Gain',\n",
       "  4: 'Chorus'},\n",
       " 'effects': [pedalboard_native.Reverb,\n",
       "  pedalboard_native.Delay,\n",
       "  pedalboard_native.Distortion,\n",
       "  pedalboard_native.Gain,\n",
       "  pedalboard_native.Chorus],\n",
       " 'total_parameters': 16,\n",
       " 'effects_to_parameters': {'Reverb': {'room_size': (0, 1),\n",
       "   'damping': (0, 1),\n",
       "   'wet_level': (0, 1),\n",
       "   'dry_level': (0, 1),\n",
       "   'width': (0, 1),\n",
       "   'freeze_mode': (0, 1)},\n",
       "  'Delay': {'delay_seconds': (0, 2), 'feedback': (0, 1), 'mix': (0, 1)},\n",
       "  'Chorus': {'rate_hz': (0, 100),\n",
       "   'depth': (0, 1),\n",
       "   'centre_delay_ms': (1, 30),\n",
       "   'feedback': (0, 1),\n",
       "   'mix': (0, 1)},\n",
       "  'Distortion': {'drive_db': (0, 100)},\n",
       "  'Gain': {'gain_db': (-12, 12)}}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metadata = generator.get_metadata()\n",
    "display(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extractor Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature extractor is built into the data generator class so it runs automatically when you run ```generator.create_data()``` \n",
    "\n",
    "But here is some demo code in case you run into problems using it anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pedalboard.io import ReadableAudioFile\n",
    "from dataset.feature_extractor_torch import FeatureExtractorTorch\n",
    "import numpy as np\n",
    "# define instance of feature extractor\n",
    "feature_extractor = FeatureExtractorTorch()\n",
    "sample_rate = 16000\n",
    "# read in audio path\n",
    "dry_tone_path = \"demo_data/guitar_acoustic_017-102-050.wav\"\n",
    "with ReadableAudioFile(dry_tone_path) as f:\n",
    "    # re sample the audio file to match the sample rate, pretrained model is sampled at 16000\n",
    "    re_sampled = f.resampled_to(sample_rate)\n",
    "    dry_tone = np.squeeze(re_sampled.read(int(sample_rate * f.duration)),axis=0)\n",
    "    re_sampled.close()\n",
    "    f.close()\n",
    "# read in features\n",
    "features = feature_extractor.get_features(dry_tone)\n",
    "# features extracted are log mel spectrogram, loudness, and fundamental frequency (f0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Prediction Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.parameter_prediction import ParameterPrediction\n",
    "param_mask = metadata['parameter_mask_idx']\n",
    "num_parameters = metadata['total_parameters']\n",
    "num_effects = len(metadata['effect_to_idx'].keys())\n",
    "batch_size=1\n",
    "model = ParameterPrediction(num_effects,num_parameters,param_mask,batch_size=batch_size).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the parameter prediction model on a sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.parameter_prediction import Trainer\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "batch_size = 1\n",
    "train_loader = DataLoader(demo_dataset, batch_size=batch_size, shuffle=True)\n",
    "loss_fn_effect = CrossEntropyLoss()\n",
    "loss_fn_params = MSELoss()\n",
    "optimizer = Adam(model.parameters(),.00001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.1)\n",
    "trainer = Trainer(model, metadata,lambda_=.65)\n",
    "trainer.train(model, train_loader, train_loader, loss_fn_effect, loss_fn_params, optimizer, scheduler, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After Training we can use the post processor to process model outputs into pedalboard effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry = demo_dataset[0]\n",
    "wet_tone_feat = entry[\"wet_tone\"]\n",
    "dry_tone_feat = entry[\"dry_tone\"]\n",
    "\n",
    "out,  effect, params = model(wet_tone_feat['spectrogram'].to(device),dry_tone_feat['spectrogram'].to(device))\n",
    "display(out.shape)\n",
    "display(effect)\n",
    "display(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.parameter_prediction import PostProcessor\n",
    "post_processor = PostProcessor(metadata)\n",
    "wet_tone, predicted_effect = post_processor.process_audio_from_outputs(effect,params[0],dry_tone_feat['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "ipd.Audio(data=wet_tone,rate=sample_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tone-grabber-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
